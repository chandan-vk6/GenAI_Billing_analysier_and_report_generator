{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: streamlit in /home/asi/.local/lib/python3.10/site-packages (1.36.0)\n",
      "Requirement already satisfied: plotly in /home/asi/.local/lib/python3.10/site-packages (5.22.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /home/asi/.local/lib/python3.10/site-packages (3.9.0)\n",
      "Requirement already satisfied: seaborn in /home/asi/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Collecting fpdf\n",
      "  Using cached fpdf-1.7.2.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /home/asi/.local/lib/python3.10/site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /home/asi/.local/lib/python3.10/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in /home/asi/.local/lib/python3.10/site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.0)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /home/asi/.local/lib/python3.10/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/lib/python3/dist-packages (from streamlit) (9.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/asi/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/asi/.local/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/asi/.local/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/asi/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.7.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (4.4.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/asi/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: jinja2 in /home/asi/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->groq) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->groq) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.18.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/asi/.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/asi/.local/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/asi/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/asi/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/asi/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/asi/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Building wheels for collected packages: fpdf\n",
      "  Building wheel for fpdf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40725 sha256=1e4d39937b97c8a218d9c454607be9f5cfd93c6fe90c7f70d46f8c07719ec24f\n",
      "  Stored in directory: /home/asi/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
      "Successfully built fpdf\n",
      "Installing collected packages: fpdf\n",
      "Successfully installed fpdf-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install streamlit plotly pandas matplotlib seaborn fpdf groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import requests\n",
    "from fpdf import FPDF\n",
    "import io\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from PIL import Image\n",
    "import base64\n",
    "import numpy as np\n",
    "import os \n",
    "import tempfile\n",
    "import plotly.io as pio\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Assuming you have set up Groq API access\n",
    "from groq import Groq\n",
    "\n",
    "# Set up Groq client (you'll need to handle API key securely)\n",
    "groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    if file.name.endswith('.csv'):\n",
    "        df = pd.read_csv(file)\n",
    "    elif file.name.endswith(('.xls', '.xlsx')):\n",
    "        df = pd.read_excel(file)\n",
    "    else:\n",
    "        st.error(\"Unsupported file format. Please upload a CSV or Excel file.\")\n",
    "        return None\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Remove duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Handle missing values\n",
    "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    date_columns = df.select_dtypes(include=['object']).columns\n",
    "    for col in date_columns:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Standardize column names\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    def serialize(obj):\n",
    "        if isinstance(obj, (np.int64, np.int32, np.int16, np.int8)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float64, np.float32)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.bool_):\n",
    "            return bool(obj)\n",
    "        elif isinstance(obj, (pd.Timestamp, pd.Timedelta)):\n",
    "            return str(obj)\n",
    "        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n",
    "\n",
    "    validation_results = {\n",
    "        \"missing_values\": df.isnull().sum().to_dict(),\n",
    "        \"duplicate_rows\": int(df.duplicated().sum()),  # Convert to int\n",
    "        \"column_types\": df.dtypes.astype(str).to_dict(),\n",
    "        \"unique_values\": {col: int(df[col].nunique()) for col in df.columns},  # Convert to int\n",
    "        \"value_ranges\": {\n",
    "            col: {\"min\": serialize(df[col].min()), \"max\": serialize(df[col].max())}\n",
    "            for col in df.select_dtypes(include=[np.number]).columns\n",
    "        }\n",
    "    }\n",
    "    return validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualizations(df):\n",
    "    figures = []\n",
    "\n",
    "    # Set a white background for all plots\n",
    "    pio.templates.default = \"plotly_white\"\n",
    "\n",
    "    # Helper function to find a column by potential names\n",
    "    def find_column(potential_names):\n",
    "        for name in potential_names:\n",
    "            if name in df.columns:\n",
    "                return name\n",
    "        return None\n",
    "\n",
    "    # 1. Histogram of Billing Amounts\n",
    "    amount_col = find_column(['Amount', 'amount', 'billing_amount', 'total'])\n",
    "    if amount_col:\n",
    "        fig = px.histogram(df, x=amount_col, title=f'Distribution of {amount_col}')\n",
    "        fig.update_traces(marker_line_color=\"black\", marker_line_width=1)\n",
    "        figures.append((f\"Histogram of {amount_col}\", fig))\n",
    "\n",
    "    # 2. Bar Chart of Department-wise Billing\n",
    "    dept_col = find_column(['Department', 'department', 'dept'])\n",
    "    if dept_col and amount_col:\n",
    "        dept_billing = df.groupby(dept_col)[amount_col].sum().sort_values(ascending=False)\n",
    "        fig = px.bar(dept_billing, x=dept_billing.index, y=dept_billing.values, \n",
    "                     title=f'Total {amount_col} by {dept_col}')\n",
    "        figures.append((f\"Bar Chart of {dept_col}-wise {amount_col}\", fig))\n",
    "\n",
    "    # 3. Heatmap of Customer Billing Activity\n",
    "    customer_col = find_column(['Customer Name', 'customer', 'client'])\n",
    "    date_col = find_column(['Billing Date', 'date', 'transaction_date'])\n",
    "    if customer_col and date_col and amount_col:\n",
    "        customer_activity = df.pivot_table(values=amount_col, index=customer_col, \n",
    "                                           columns=date_col, aggfunc='sum', fill_value=0)\n",
    "        fig = px.imshow(customer_activity, title=f'Heatmap of {customer_col} {amount_col} Activity')\n",
    "        figures.append((f\"Heatmap of {customer_col} {amount_col} Activity\", fig))\n",
    "\n",
    "    # 4. Timeline of Billing Cycle\n",
    "    if date_col and amount_col:\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "        daily_billing = df.groupby(date_col)[amount_col].sum().reset_index()\n",
    "        fig = px.line(daily_billing, x=date_col, y=amount_col, title=f'Timeline of {amount_col} Cycle')\n",
    "        figures.append((f\"Timeline of {amount_col} Cycle\", fig))\n",
    "\n",
    "    # 5. Pie Chart of Payment Status\n",
    "    status_col = find_column(['Status', 'status', 'payment_status'])\n",
    "    if status_col:\n",
    "        status_counts = df[status_col].value_counts()\n",
    "        fig = px.pie(values=status_counts.values, names=status_counts.index, \n",
    "                     title=f'Distribution of {status_col}')\n",
    "        figures.append((f\"Pie Chart of {status_col}\", fig))\n",
    "\n",
    "    # Ensure all figures have a white background\n",
    "    for _, fig in figures:\n",
    "        fig.update_layout(plot_bgcolor='white', paper_bgcolor='white')\n",
    "\n",
    "    return figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llm_report(df, prompt, validation_results):\n",
    "    # Convert DataFrame to JSON\n",
    "    df_json = df.to_json(orient='records', date_format='iso')\n",
    "    \n",
    "    # Prepare the message for the LLM\n",
    "    message = f\"\"\"\n",
    "    Analyze the following billing data and validation results:\n",
    "    \n",
    "    Data: {df_json}\n",
    "    \n",
    "    Validation Results: {json.dumps(validation_results, default=str)}\n",
    "    \n",
    "    User Prompt: {prompt}\n",
    "    \n",
    "    Generate a detailed report analyzing the billing data, addressing the user's prompt, \n",
    "    and providing insights based on the data and validation results. \n",
    "    \n",
    "    Structure your report with the following sections, using double asterisks (**) to denote section headers:\n",
    "    \n",
    "    1. **Summary**\n",
    "    2. **Spending Trends**\n",
    "    3. **Insights**\n",
    "    4. **Recommendations**\n",
    "    \"\"\"\n",
    "    # Call Groq API\n",
    "    response = groq_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a data analyst specializing in billing data analysis.\"},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "        model=\"llama3-70b-8192\",\n",
    "    )\n",
    "    \n",
    "    # After getting the response from the LLM\n",
    "    report_text = response.choices[0].message.content\n",
    "    \n",
    "    # Create visualizations\n",
    "    figures = create_visualizations(df)\n",
    "    \n",
    "    # Combine report text with visualizations\n",
    "    combined_report = report_text\n",
    "    # for title, _ in figures:\n",
    "    #     combined_report += f\"\\n\\n[Insert {title} here]\\n\\n\"\n",
    "    \n",
    "    return combined_report, figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 15)\n",
    "        self.cell(0, 10, 'Billing Data Analysis Report', 0, 1, 'C')\n",
    "        self.ln(5)\n",
    "\n",
    "    def footer(self):\n",
    "        self.set_y(-15)\n",
    "        self.set_font('Arial', 'I', 8)\n",
    "        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_report(report_text, figures):\n",
    "    pdf = PDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    \n",
    "    # Split the report text into sections\n",
    "    sections = report_text.split('\\n\\n')\n",
    "    \n",
    "    for i, section in enumerate(sections):\n",
    "        # Check if the section is a header\n",
    "        if section.strip().startswith('**') and section.strip().endswith('**'):\n",
    "            pdf.set_font(\"Arial\", 'B', 14)\n",
    "            pdf.cell(0, 10, section.strip('*'), 0, 1)\n",
    "            pdf.set_font(\"Arial\", size=12)\n",
    "        else:\n",
    "            pdf.multi_cell(0, 10, section)\n",
    "        \n",
    "        # After each section, check if we have a figure to insert\n",
    "        if i < len(figures):\n",
    "            fig_title, fig = figures[i]\n",
    "            img_bytes = fig.to_image(format=\"png\", scale=2)  # Increased scale for better quality\n",
    "            \n",
    "            # Create a temporary file\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmpfile:\n",
    "                tmpfile.write(img_bytes)\n",
    "                tmpfile_name = tmpfile.name\n",
    "\n",
    "            # Add a new page for the figure if near the bottom of the page\n",
    "            if pdf.get_y() > 180:\n",
    "                pdf.add_page()\n",
    "\n",
    "            # Add the image to the PDF\n",
    "            pdf.image(tmpfile_name, x=10, y=pdf.get_y()+10, w=190)\n",
    "            pdf.set_y(pdf.get_y() + 140)  # Increased space after image\n",
    "            pdf.set_font(\"Arial\", 'I', 10)\n",
    "            pdf.cell(0, 10, fig_title, 0, 1, 'C')  # Add figure title\n",
    "            pdf.set_font(\"Arial\", size=12)\n",
    "            pdf.ln(10)  # Add extra space after the figure\n",
    "            \n",
    "            # Remove the temporary file\n",
    "            os.unlink(tmpfile_name)\n",
    "    \n",
    "    pdf_output = pdf.output(dest='S').encode('latin-1')\n",
    "    return pdf_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 18:46:18.318 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/asi/.local/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-07-10 18:46:18.319 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    st.title(\"Billing Data Analysis Report Generator\")\n",
    "\n",
    "    uploaded_file = st.file_uploader(\"Choose a CSV or Excel file\", type=['csv', 'xlsx', 'xls'])\n",
    "    \n",
    "    if 'df' not in st.session_state:\n",
    "        st.session_state.df = None\n",
    "    if 'validation_results' not in st.session_state:\n",
    "        st.session_state.validation_results = None\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        df = load_data(uploaded_file)\n",
    "        \n",
    "        if df is not None:\n",
    "            st.write(\"Data Preview (Before Preprocessing):\")\n",
    "            st.write(df.head())\n",
    "\n",
    "            # Initialize validation_results here\n",
    "            st.session_state.validation_results = validate_data(df)\n",
    "\n",
    "            st.subheader(\"Data Preprocessing\")\n",
    "            if st.button(\"Preprocess Data\"):\n",
    "                st.session_state.df = preprocess_data(df)\n",
    "                st.session_state.validation_results = validate_data(st.session_state.df)\n",
    "                st.write(\"Data Preview (After Preprocessing):\")\n",
    "                st.write(st.session_state.df.head())\n",
    "                st.write(\"Validation Results:\")\n",
    "                st.json(st.session_state.validation_results)\n",
    "\n",
    "    st.subheader(\"Analysis Prompt\")\n",
    "    prompt = st.text_area(\"Enter your question or what you'd like to know about the billing data:\", \n",
    "    \"\"\"Analyze the billing data to ensure accuracy and timeliness.Identify any discrepancies or unusual patterns You can assume and utilize relevant metrics to analyze the billing data, such as billing cycle times, payment discrepancies, late  payment occurrences, and average payment amounts.\"\"\", height=100)\n",
    "    \n",
    "    if st.button(\"Generate Report\"):\n",
    "        if prompt and st.session_state.df is not None:\n",
    "            with st.spinner(\"Generating report...\"):\n",
    "                report_text, figures = generate_llm_report(st.session_state.df, prompt, st.session_state.validation_results)\n",
    "                \n",
    "                st.subheader(\"Generated Report\")\n",
    "                st.write(report_text)\n",
    "                \n",
    "                for title, fig in figures:\n",
    "                    st.subheader(title)\n",
    "                    st.plotly_chart(fig)\n",
    "                \n",
    "                pdf_output = create_pdf_report(report_text, figures)\n",
    "                \n",
    "                st.download_button(\n",
    "                    label=\"Download PDF Report\",\n",
    "                    data=pdf_output,\n",
    "                    file_name=\"billing_analysis_report.pdf\",\n",
    "                    mime=\"application/pdf\"\n",
    "                )\n",
    "        else:\n",
    "            st.warning(\"Please enter an analysis prompt and ensure data is preprocessed before generating the report.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
